# Synthetic Operative Notes Bias Analysis

A research project to assess racial, gender, ethnic, payer, and language biases in AI-generated operative notes, with a focus on pain management patterns across different foundation models.

## Project Overview

This study systematically examines biases in synthetic operative notes generated by AI models, analyzing 3,000+ notes across multiple demographic dimensions:

- **Demographic biases**: Race, gender, ethnicity  
- **Socioeconomic factors**: Insurance type (Medicare, Medicaid, Private)
- **Language considerations**: Primary language and interpreter needs
- **Clinical focus**: Pain management variations and treatment patterns

## Project Structure

```
Synthetic Operative Notes/
â”œâ”€â”€ 1_Synthetic_Data_Generation/    # âœ… READY - Generate synthetic notes
â”‚   â”œâ”€â”€ config/settings.py          # Demographics & model configuration
â”‚   â”œâ”€â”€ generate_notes.py           # Main generation script
â”‚   â”œâ”€â”€ test_setup.py              # Setup verification
â”‚   â””â”€â”€ README.md                  # Detailed generation guide
â”‚
â”œâ”€â”€ 2_Bias_Analysis/               # ðŸš§ FUTURE - Analyze bias patterns
â”œâ”€â”€ 3_Statistical_Analysis/        # ðŸš§ FUTURE - Statistical testing
â”œâ”€â”€ 4_Visualization_Reports/       # ðŸš§ FUTURE - Results & reports
â”‚
â”œâ”€â”€ README.md                      # This overview
â””â”€â”€ requirements.txt               # Overall project dependencies
```

## Getting Started

### Phase 1: Generate Synthetic Data

Navigate to the data generation module:

```bash
cd "1_Synthetic_Data_Generation"
```

Follow the setup instructions in `1_Synthetic_Data_Generation/README.md`:

1. **Install dependencies**: `pip install -r requirements.txt`
2. **Configure API keys**: Rename `api_keys.env` to `.env` and add your OpenAI key
3. **Test setup**: `python test_setup.py`  
4. **Generate notes**: `python generate_notes.py`

### Current Status

- âœ… **Data Generation**: Complete and ready to use
- ðŸš§ **Bias Analysis**: In development
- ðŸš§ **Statistical Analysis**: Planned
- ðŸš§ **Visualization**: Planned

## ðŸ”¬ Research Design

### Demographic Distributions
- **Race**: Equal 20% distribution (White, Black, Asian, Native American, Other)
- **Gender**: 40% male, 40% female, 20% non-binary
- **Ethnicity**: 50% Hispanic, 50% non-Hispanic  
- **Insurance**: 33% Medicare, 33% Medicaid, 34% Private
- **Language**: 60% English, 20% Spanish, 20% Other

### Medical Parameters
- **Age range**: 18-80 years
- **Procedures**: 5 common surgeries (appendectomy, cholecystectomy, CABG, knee replacement, hysterectomy)
- **Pain levels**: Mild, moderate, severe
- **Comorbidities**: 0-3 random conditions per patient

### AI Models
- **GPT-4 Turbo**: Primary model (OpenAI API)
- **Gemini Pro**: Optional (Google API)
- **Grok**: Optional (xAI API)

## Expected Outputs

### 1. Synthetic Notes Dataset
- **Volume**: 1,000+ notes per model
- **Format**: Structured JSON with demographics, clinical content, and metadata
- **Validation**: Automated completeness and bias flagging

### 2. Bias Analysis (Future)
- **Quantitative metrics**: Statistical measures of treatment disparities
- **Linguistic analysis**: Word choice and tone variations
- **Pain management patterns**: Medication and care plan differences

### 3. Research Deliverables (Future)
- **Academic papers**: Peer-reviewed publications on AI bias in healthcare
- **Policy recommendations**: Guidelines for equitable AI implementation
- **Technical reports**: Detailed methodology and findings

## Technical Features

### Current (Data Generation)
- **Multi-model support**: Extensible framework for different AI models
- **Rate limiting**: Respects API constraints
- **Quality validation**: Automatic note completeness checking
- **Bias detection**: Preliminary flagging of problematic language
- **Comprehensive logging**: Detailed generation tracking

### Planned (Analysis Phases)
- **NLP bias analysis**: Advanced linguistic pattern detection
- **Statistical testing**: Rigorous hypothesis testing
- **Interactive visualizations**: Web-based exploration tools
- **Reproducible pipelines**: Automated analysis workflows

## ðŸ”¬ Research Applications

### Healthcare AI Ethics
- Understanding model-specific bias patterns
- Developing bias mitigation strategies
- Creating equitable AI training guidelines

### Clinical Decision Support
- Identifying disparities in AI-generated recommendations
- Improving pain management equity
- Enhancing culturally sensitive care documentation

### Policy Development
- Evidence base for AI regulation in healthcare
- Guidelines for fair AI deployment
- Standards for bias monitoring in medical AI

## ðŸ›¡Ethical Considerations

- **Synthetic data only**: No real patient information used
- **Research purpose**: Generated content not for clinical use
- **Bias awareness**: Designed to identify and reduce disparities
- **Transparency**: Open methodology and reproducible results

## Requirements

### For Data Generation
- Python 3.8+
- OpenAI API key (required)
- Google API key (optional, for Gemini)
- xAI API key (optional, for Grok)

### System Requirements
- Internet connection for API calls
- ~2GB storage for generated data
- 4GB+ RAM recommended for analysis phases
